{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expectation\n",
    "\n",
    "**Definition**: The expected value or mean or first moment of a random variable ${X}$ which has pdf ${f_{X}}$ and CDF ${F_{X}}$ is defined as ${E(X)= \\sum xf(x)}$ for all ${x}$ in the range of ${X}$. In case of continuous random variable ${X, E(X)= \\int xdF(x)= \\int xf(x)dx}$. ${E(X)}$ is denoted as ${\\mu_{X}}$.\n",
    "\n",
    "${E(X)}$ can be thought of as a one number summary of the distribution. If we take ${n}$ i.i.d samples from a distribution say ${X_{1}, X_{2},...,X_{n}}$,then ${E(X)\\approx \\frac{\\sum_{i=1}^{n}X_{i}}{n}}$. The larger the n is, more accurate the estimate.\n",
    "\n",
    "${E(X)}$ is said to exist if ${\\int_{x}\\mid x\\mid dF(x) < \\infty}$. Therefore, Cauchy distribution doesn't have an expectation. If samples are collected from Cauchy distibution and their mean is taken, and if this process is repeated several times we observe that mean doesn't settle down.\n",
    "\n",
    "Suppose someone tells us that he has observed a value of a random variable ${X}$ and he tells us the distribution to which the random variable belongs and he asks us to guess the value and report the answer in form of ${A\\pm B}$. Then we would have most chances of guessing the value correctly if we report our answer such that ${A}$ is ${E(X)}$ and ${B}$ is ${\\sigma(X)}$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem**: If ${Y}$ and ${X}$ are random variables such that ${Y= r(X)}$,then ${E(Y)= E(r(X))= \\int r(x)dF(x)}$.\n",
    "\n",
    "Example: Let's say we toss a coin n times which has 1 on one side and 0 on the other. The probability that 1 shows up after a toss is p. I say that I pay you 10 times the number that shows up on the coin. Define X as the number of times 1 shows up and Y as the amount I pay you. ${\\therefore Y=10X}$. The expected amount you earn is 10 times the expected number of times the number 1 shows up. ${f(x)=  C_{x}^{n}p^{x}(1-p)^{n-x}, E(X)= \\sum x C_{x}^{n}p^{x}(1-p)^{n-x}}$. Notice that ${X = \\sum X_{i}}$ where ${X_{i}}$ is the number which is shown in i'th toss. Then ${E(X) = E( \\sum X_{i})= \\sum E(X_{i})= \\sum 1p+0(1-p)= np}$. Therefore the expected amount you earn is ${10np}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/moment.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Properties of Expectations\n",
    "\n",
    "**Theorem:** If ${X_{1}, X_{2},...,X_{n}}$ are random variables and ${a_{1}, a_{2},...,a_{n}}$ are constants then, ${E\\sum_{i}a_{i}X_{i}= \\sum a_{i}E(X_{i})}$. This is a simple consequence of properties of integrals or summations.\n",
    "\n",
    "**Theorem:** If ${X_{1}, X_{2},...,X_{n}}$ are independent random variables then, ${E(\\Pi_{i}X_{i})= \\Pi E(X_{i})}$. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
