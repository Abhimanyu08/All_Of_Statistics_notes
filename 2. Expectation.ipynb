{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expectation\n",
    "\n",
    "**Definition**: The expected value or mean or first moment of a random variable ${X}$ which has pdf ${f_{X}}$ and CDF ${F_{X}}$ is defined as ${E(X)= \\sum xf(x)}$ for all ${x}$ in the range of ${X}$. In case of continuous random variable ${X, E(X)= \\int xdF(x)= \\int xf(x)dx}$. ${E(X)}$ is denoted as ${\\mu_{X}}$.\n",
    "\n",
    "${E(X)}$ can be thought of as a one number summary of the distribution. If we take ${n}$ i.i.d samples from a distribution say ${X_{1}, X_{2},...,X_{n}}$,then ${E(X)\\approx \\frac{\\sum_{i=1}^{n}X_{i}}{n}}$. The larger the n is, more accurate the estimate.\n",
    "\n",
    "${E(X)}$ is said to exist if ${\\int_{x}\\mid x\\mid dF(x) < \\infty}$. Therefore, Cauchy distribution doesn't have an expectation. If samples are collected from Cauchy distibution and their mean is taken, and if this process is repeated several times we observe that mean doesn't settle down.\n",
    "\n",
    "Suppose someone tells us that he has observed a value of a random variable ${X}$ and he tells us the distribution to which the random variable belongs and he asks us to guess the value and report the answer in form of ${A\\pm B}$. Then we would have most chances of guessing the value correctly if we report our answer such that ${A}$ is ${E(X)}$ and ${B}$ is ${\\sigma(X)}$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem**: If ${Y}$ and ${X}$ are random variables such that ${Y= r(X)}$,then ${E(Y)= E(r(X))= \\int r(x)dF(x)}$.\n",
    "\n",
    "Example: Let's say we toss a coin n times which has 1 on one side and 0 on the other. The probability that 1 shows up after a toss is p. I say that I pay you 10 times the number that shows up on the coin. Define X as the number of times 1 shows up and Y as the amount I pay you. ${\\therefore Y=10X}$. The expected amount you earn is 10 times the expected number of times the number 1 shows up. ${f(x)=  C_{x}^{n}p^{x}(1-p)^{n-x}, E(X)= \\sum x C_{x}^{n}p^{x}(1-p)^{n-x}}$. Notice that ${X = \\sum X_{i}}$ where ${X_{i}}$ is the number which is shown in i'th toss. Then ${E(X) = E( \\sum X_{i})= \\sum E(X_{i})= \\sum 1p+0(1-p)= np}$. Therefore the expected amount you earn is ${10np}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/moment.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Properties of Expectations\n",
    "\n",
    "**Theorem:** If ${X_{1}, X_{2},...,X_{n}}$ are random variables and ${a_{1}, a_{2},...,a_{n}}$ are constants then, ${E\\sum_{i}a_{i}X_{i}= \\sum a_{i}E(X_{i})}$. This is a simple consequence of properties of integrals or summations.\n",
    "\n",
    "**Theorem:** If ${X_{1}, X_{2},...,X_{n}}$ are independent random variables then, ${E(\\Pi_{i}X_{i})= \\Pi E(X_{i})}$. \n",
    "\n",
    "**Note**: The summation doesn't require any independence but the product does"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance and Covariance\n",
    "\n",
    "**Definition** The variance measures the spread of the distribution and is defined as ${V(X)= E(X-\\mu)^2}$\n",
    "\n",
    "**Note** Intutitively we may think that ${E(X-\\mu)}$ should be the measure of the spread but this quantity is equal to 0.\n",
    "\n",
    "**Definition** The standard deviation is defined as ${\\sigma(x)= \\sqrt[]{E(X-\\mu)^2}}$\n",
    "\n",
    "**Theorem** The variance has following properties:\n",
    "\n",
    "- ${V(X) = E(X-\\mu)^2 = E(X^2- 2\\mu X + \\mu^2) = E(X^2) - 2\\mu E(X) + (E(X))^2 = E(X^2) - E(X)^2 = E(X^2) - \\mu^2}$\n",
    "- if ${a}$ and ${b}$ are constants then ${V(aX+b) = a^2V(X)}$.(Variance of a constant is 0 because a constant never varies)\n",
    "- If ${X_{1}, X_{2},...,X_{n}}$ are independent random variables and ${a_{1}, a_{2},...,a_{n}}$ are constants then, \n",
    "${V\\sum_{i=1}^{n}a_{i}X_{i} = \\sum_{i=1}^{n}a_{i}^2V(X_{i})}$\n",
    "\n",
    "**Note**: In this case the summation requires independence. This is because if n random variable vary their variations will be centered around the mean whether they are indepenedent or not, only their \"spread\" of variation will change depending on their independence or dependence. If they are indepenedent their spread will remain the same but if they are dependent, for eg. suppose ${X_{1}}$ and ${X_{2}}$ are dependent then values of either will put a restriction on the values of the other.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition** If ${X_{1}, X_{2},...,X_{n}}$ are random variables, then the **sample mean** is defined as ${\\overline{X} = \\frac{1}{n}\\sum_{i=1}^{n}X_{i}}$. The **sample variance** is defined as ${S_{n}^{2} = \\frac{1}{n-1}\\sum_{i=1}^{n}(X_{i}- \\overline X_{n})^2}$\n",
    "\n",
    "**Theorem** If ${X_{1}, X_{2},...,X_{n}}$ are i.i.d and ${E(X_{i})= \\mu,\\, V(X_{i})= \\sigma^{2}}$, then ${E(\\overline X_{n})= \\mu,\\, V(\\overline X_{n})= \\frac{\\sigma^{2}}{n},\\, E(S_{n}^2)= \\sigma^2}$.\n",
    "\n",
    "This shows that if we have a n sized sample from a distribution, then we can estimate the mean of the distribution by taking the mean of the samples. We want our estimation of mean to be pretty close to the original mean and therefore we want it to vary less from sample to sample. This can be done by collecting a large sample because ${V(\\overline X_{n})\\propto \\frac{1}{n}}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance and Correlation\n",
    "\n",
    "Let ${X}$ and ${Y}$ be random variables with mean ${\\mu_{X}}$ and ${\\mu{Y}}$ respectively and standard deviations ${\\sigma_{X}}$ and ${\\sigma_{Y}}$. Then the covariance between ${X}$ and ${Y}$ is defined as \n",
    "${Cov(X,Y) = E(X-\\mu_{X})(Y-\\mu_{Y})}$ and the correlation is defined as ${\\rho = \\large\\frac{Cov(X,Y)}{\\sigma_{X}\\sigma_{Y}}}$\n",
    "\n",
    "**Theorem**: \n",
    "\n",
    "- ${Cov(X,Y) = E(XY) - E(X)E(Y)}$\n",
    "- ${-1\\leq \\rho\\leq 1}$\n",
    "\n",
    "![](images/covriance.JPG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectation and Variance of some Important Random Variables\n",
    "\n",
    "![](images\\expectations.JPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
